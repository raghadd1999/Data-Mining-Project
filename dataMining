dataset= read.csv("~/data_banknote_authentication.txt", header=FALSE) names(dataset)[1] <- "variance"
names(dataset)[2] <- "skewness"
names(dataset)[3] <- "curtosis"
names(dataset)[4] <- "entropy"
names(dataset)[5] <- "class"
is.na(dataset) // Check missing values sum(is.na(dataset))
 install.packages("outliers") library("outliers")
Outent = outlier(dataset$entropy, logical =TRUE) sum(Outent)
Find_outlier = which(Outent ==TRUE, arr.ind = TRUE) dataset= dataset[-Find_outlier,]
Outent1 = outlier(dataset$variance, logical =TRUE) sum(Outent1)
Find_outlier1 = which(Outent1 ==TRUE, arr.ind = TRUE) dataset= dataset[-Find_outlier1,]
Outent2 = outlier(dataset$skewness, logical =TRUE) sum(Outent2)
Find_outlier2 = which(Outent2 ==TRUE, arr.ind = TRUE) dataset= dataset[-Find_outlier2,]
Outent3 = outlier(dataset$curtosis, logical =TRUE)
 sduamta(sOeut$teclnats3s)= factor(dataset$class,
Find_outlier3 = which(Outent3 ==TRUE, arr.ind = TRUE) levels = c(0, 1),
dataset= dataset[-Find_outlier3,]
write.csv(dataset,"~/dataset.txt", row.names=FALSE)
labels = c("Yes", "No"))
// Remove outliers
// Encode values
Data mining task (Decision Tree):
dataset= read.csv("~/dataset.txt", header=TRUE)
str(dataset)
set.seed(1234)
ind <- sample(2, nrow(dataset), replace = TRUE, prob=c(0.6,0.4)) //Split data into training and testing trainData <- dataset[ind==1,]
testData <- dataset[ind==2,]
install.packages("party")
library("party")
myFormula <- class~ entropy + curtosis + variance + skewness
m_ctree1 <- ctree(myFormula, data= trainData) table(predict(m_ctree1), trainData$class) print(m_ctree1)
plot(m_ctree1)
table(trainData$class, useNA ="ifany")
Data Evaluation (Decision Tree):
// Build decision tree based on training data
// To know how many rows for each class in training data
testPred1 = predict(m_ctree1, newdata= testData) // Predict the classes for testing data based on training str(testData)
install.packages("e1071") install.packages("caret") library(e1071)
library(caret)
coMA0 <- confusionMatrix(testPred1, reference = testData$class)
percentage of its accuracy, sensitivity, etc.
acc <- coMA0$byClass
print(acc)
print(coMA0)
Data Pre-Processing (KNN):
dataset= read.csv("~/data_banknote_authentication.txt", header=FALSE) names(dataset)[1] <- "variance"
names(dataset)[2] <- "skewness" names(dataset)[3] <- "curtosis" names(dataset)[4] <- "entropy" names(dataset)[5] <- "class"
is.na(dataset) // Check missing values sum(is.na(dataset))
install.packages("outliers") library("outliers")
Outent = outlier(dataset$entropy, logical =TRUE) sum(Outent)
Find_outlier = which(Outent ==TRUE, arr.ind = TRUE) dataset= dataset[-Find_outlier,] Outent1 = outlier(dataset$variance, logical =TRUE) sum(Outent1)
Find_outlier1 = which(Outent1 ==TRUE, arr.ind = TRUE) dataset= dataset[-Find_outlier1,] Outent2 = outlier(dataset$skewness, logical =TRUE) sum(Outent2)
Find_outlier2 = which(Outent2 ==TRUE, arr.ind = TRUE) dataset= dataset[-Find_outlier2,] Outent3 = outlier(dataset$curtosis, logical =TRUE) sum(Outent3)
Find_outlier3 = which(Outent3 ==TRUE, arr.ind = TRUE)
dataset= dataset[-Find_outlier3,]
write.csv(dataset,"~/dataset1.txt", row.names=FALSE)
// Evaluate the model and gives
//Remove Outliers
Data mining task (KNN):
set.seed(1234)
ind <- sample(2, nrow(dataset), replace = TRUE, prob=c(0.6,0.4)) trainData <- dataset[ind==1,]
testData <- dataset[ind==2,]
trainDataC <- dataset[ind==1,5]
testDataC <- dataset[ind==2,5]
#install.packages("class")
library("class")
pr <- knn(train = trainData,test=testData,cl=trainDataC,k=5)
Data Evaluation (KNN): #install.packages(“e1071”)
#install.packages("caret")
library(e1071)
library(caret)
//Split data into training and testing
//Classes for training/testing sets
//Apply knn method
confusionMatrix(table(pr ,testDataC)) // Evaluate the model and gives percentage of its accuracy.
acc1 <- confusionMatrix(table(pr ,testDataC))$byClass // Evaluate the model and gives percentage of sensitivity, etc.
print(acc1)